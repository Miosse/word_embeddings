{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk\n",
    "import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'data/QueryResults3_new.csv'\n",
    "df1 = pd.read_csv(file1,index_col=['Id'])\n",
    "\n",
    "import mes_fonctions_final2 as stt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "StopWord = stt.load_stop_word()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/!\\ Ajout des features en cours\n"
     ]
    }
   ],
   "source": [
    "Y_tags, Y_tags_voc = stt.genere_target_dummy_and_vocabulary(data=df1, min_df=300)\n",
    "Tags_freq = stt.genere_df_target_tags_freq(data=df1, min_df=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions de pré-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import EnglishStemmer\n",
    "stemmer = EnglishStemmer()\n",
    "\n",
    "def preProcess_remove_Code(html_in):\n",
    "    # Chargement du module BeautifulSoup pour le parsing des données HTML\n",
    "    from bs4 import BeautifulSoup\n",
    "    html_in_soup = BeautifulSoup(html_in, 'html.parser')\n",
    "\n",
    "    # Suppression des blocs de Code\n",
    "    for h_code in html_in_soup.find_all('code'):\n",
    "        h_code.decompose()\n",
    "\n",
    "    return html_in_soup.get_text().lower()\n",
    "\n",
    "\n",
    "def preProcess_keep_Code(html_in):\n",
    "    # Chargement du module BeautifulSoup pour le parsing des données HTML\n",
    "    from bs4 import BeautifulSoup\n",
    "    html_in_soup = BeautifulSoup(html_in, 'html.parser')\n",
    "\n",
    "    return html_in_soup.get_text().lower()\n",
    "\n",
    "# Le préprocessing :\n",
    "#   - nettoie le html\n",
    "#   - supprime les blocs de Code\n",
    "#   - ne prend que la partie textuelle du html\n",
    "#   - renvoie ce texte en minuscule\n",
    "\n",
    "\n",
    "def preProcess(html_in):\n",
    "    # Chargement du module BeautifulSoup pour le parsing des données HTML\n",
    "    from bs4 import BeautifulSoup\n",
    "    html_in_soup = BeautifulSoup(html_in, 'html.parser')\n",
    "\n",
    "    # Suppression des blocs de Code\n",
    "    for h_code in html_in_soup.find_all('code'):\n",
    "        h_code.decompose()\n",
    "\n",
    "    return html_in_soup.get_text().lower()\n",
    "\n",
    "\n",
    "# Réalisation du stemming (on coupe les racines)\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "\n",
    "# La tokenisation :\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    m_token_pattern = r\"((?:(?:(?:[0-9a-zA-Z])\\.){2,}[a-zA-Z])\" +\\\n",
    "        \"|(?:(?:[0-9a-zA-Z]){2,}\\.(?:[0-9a-zA-Z]){2,}\" +\\\n",
    "        \"|(?:\\.(?:[0-9a-zA-Z]){2,}))\" +\\\n",
    "        \"|[0-9a-zA-Z-\\-\\+\\#]{2,}|w+)\"\n",
    "\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    # Nous allons utiliser le pattern pour identifier les mots\n",
    "    tokenizer = RegexpTokenizer(m_token_pattern)\n",
    "\n",
    "    # Nous lançons la séparation des mots\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    # On fait appel au stemming pour rapprocher les mots de même racine\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "\n",
    "    # Etape de nettoyage des valeurs :\n",
    "    # Nous allons supprimer les nombres sans texte,\n",
    "    def suppress_nb(x):\n",
    "        import re\n",
    "        if x is None:\n",
    "            return None\n",
    "        pattern = r'(^[\\#\\-\\+]*[0-9]*$|' + '^[0-9]*[\\#\\-\\+]*$|'+'^[0-9]*[\\#\\-\\+]?[0-9]*$|'+'^[0-9\\#\\-\\+][a-z]$|'+'^[a-z][0-9\\#\\-\\+]$|'+'^[0-9]*\\.[0-9]*$)'\n",
    "        if not(re.match(pattern, x)):\n",
    "            return x\n",
    "\n",
    "    def nettoie_points(x):\n",
    "        import re\n",
    "        if x is None:\n",
    "            return None\n",
    "\n",
    "        if (re.match(r'(^[\\.\\-\\#][a-z]*$)', x)):\n",
    "            return ''.join(list(x)[1:])\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    # Nous filtrons les nombres seuls\n",
    "    stems = list(filter(lambda x: suppress_nb(x), stems))\n",
    "    stems = [nettoie_points(x) for x in stems]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtre de X_train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout de Body_clean_token\n",
    "> On nettoie les Body en appliquant le même nettoyage que celui réalisé pour la version des BOW traditionnelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 54s, sys: 191 ms, total: 1min 55s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "df1['Body_clean_token'] = df1.Body.apply(lambda x: ' '.join(tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin Train_Split : 0:00:00.069478\n"
     ]
    }
   ],
   "source": [
    "# On sépare les données d'entrainement de celles de tests\n",
    "debut = datetime.datetime.now()\n",
    "X = df1['Body']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_tags, test_size=0.2, random_state=42 )\n",
    "fin = datetime.datetime.now()\n",
    "print(\"Fin Train_Split : {}\".format(fin-debut))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation Title / Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERSION TITLE\n",
    "X_train_Title = df1.loc[X_train.index, 'Title']\n",
    "X_test_Title = df1.loc[X_test.index, 'Title']\n",
    "\n",
    "train_title = pd.DataFrame(X_train_Title)\n",
    "test_title = pd.DataFrame(X_test_Title)\n",
    "train_title.columns = ['post']\n",
    "test_title.columns = ['post']\n",
    "\n",
    "# VERSION BODY\n",
    "###X_train_body = df1.loc[X_train.index, 'Body']\n",
    "###X_test_body = df1.loc[X_test.index, 'Body']\n",
    "X_train_body = df1.loc[X_train.index, 'Body_clean_token']\n",
    "X_test_body = df1.loc[X_test.index, 'Body_clean_token']\n",
    "\n",
    "\n",
    "train_body = pd.DataFrame(X_train_body)\n",
    "test_body = pd.DataFrame(X_test_body)\n",
    "train_body.columns = ['post']\n",
    "test_body.columns = ['post']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELMO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement du modèle pré-entrainé d'ELMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /var/folders/95/fydcf18x5rz7wljn4wqt_tq00000gn/T/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://tfhub.dev/google/elmo/2\"\n",
    "embed = hub.Module(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transformation des données Cibles par un encodage \n",
    "> On ne traite que les tags Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Y \n",
    "y1 = np.where(Y_train['python'].to_dense()==0, 'non', 'python')\n",
    "y2 = np.where(Y_test['python'].to_dense()==0, 'non', 'python')\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y1)\n",
    "\n",
    "def encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def decode(le, one_hot):\n",
    "    dec = np.argmax(one_hot, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = np.asarray(encode(le, y1))\n",
    "y_test = np.asarray(encode(le, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On transforme les features en np.array : \n",
    "x_train_title = np.asarray(X_train_Title)\n",
    "x_train_body = np.asarray(X_train_body)\n",
    "\n",
    "x_test_title = np.asarray(X_test_Title)\n",
    "x_test_body = np.asarray(X_test_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Configuration de la Partie Title\n",
    "> On paramètre le plongement de mots pour le titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Lambda, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "\n",
    "def ELMoEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
    "    #return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"tokens\", as_dict=True)[\"tokens\"]\n",
    "\n",
    "input_text_title = Input(shape=(1,), dtype=tf.string)\n",
    "embedding_title = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text_title)\n",
    "dense_title = Dense(256, activation='relu')(embedding_title)\n",
    "pred_title = Dense(2, activation='softmax')(dense_title)\n",
    "model_title = Model(inputs=[input_text_title], outputs=pred_title)\n",
    "model_title.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Partie Body\n",
    "> On paramètre le plongement de mots pour le body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "input_text_body = Input(shape=(1,), dtype=tf.string)\n",
    "embedding_body = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text_body)\n",
    "dense_body = Dense(256, activation='relu')(embedding_body)\n",
    "pred_body = Dense(2, activation='softmax')(dense_body)\n",
    "model_body = Model(inputs=[input_text_body], outputs=pred_body)\n",
    "model_body.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> On paramètre le plongement de mots pour le body nettoyé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "input_text_body = Input(shape=(1,), dtype=tf.string)\n",
    "embedding_body = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text_body)\n",
    "dense_body = Dense(256, activation='relu')(embedding_body)\n",
    "pred_body = Dense(2, activation='softmax')(dense_body)\n",
    "model_body_V2 = Model(inputs=[input_text_body], outputs=pred_body)\n",
    "model_body_V2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BODY CLEAN TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERSION BODY V2\n",
    "X_train_body_V2 = df1.loc[X_train.index, 'Body_clean_token']\n",
    "X_test_body_V2 = df1.loc[X_test.index, 'Body_clean_token']\n",
    "\n",
    "train_body_V2 = pd.DataFrame(X_train_body_V2)\n",
    "test_body_V2 = pd.DataFrame(X_test_body_V2)\n",
    "train_body_V2.columns = ['post']\n",
    "test_body_V2.columns = ['post']\n",
    "\n",
    "## X V2: \n",
    "x_train_body_V2 = np.asarray(X_train_body_V2)\n",
    "x_test_body_V2 = np.asarray(X_test_body_V2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du RNN pour le Body nettoyé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 64621s 2s/step - loss: 0.2920 - acc: 0.8949\n",
      "CPU times: user 4d 16h 57min 11s, sys: 3h 29min 41s, total: 4d 20h 26min 52s\n",
      "Wall time: 17h 57min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    history_body_V2 = model_body_V2.fit(x_train_body_V2, y_train, epochs=1, batch_size=8)\n",
    "    model_body_V2.save_weights('./MODELS/elmo-model-body_clean_token.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> L'Entrainement aura duré 18h "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du RNN pour le Titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 2171s 54ms/step - loss: 0.2742 - acc: 0.9124\n",
      "CPU times: user 3h 40min 2s, sys: 7min 50s, total: 3h 47min 53s\n",
      "Wall time: 36min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#NB_VALUES = 10\n",
    "\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    #####history_title = model_title.fit(x_train_title, y_train, epochs=1, batch_size=32)\n",
    "    history_title = model_title.fit(x_train_title, y_train, epochs=1, batch_size=8)\n",
    "    model_title.save_weights('./MODELS/elmo-model-title.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> L'Entrainement est ici beaucoup plus rapide : 36 min car il y a beaucoup moins de mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction & Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Body Clean Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1d 4h 12min 19s, sys: 53min, total: 1d 5h 5min 20s\n",
      "Wall time: 4h 28min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "### VERSION BODY CLEAN\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    model_body_V2.load_weights('./MODELS/elmo-model-body_clean_token.h5')  \n",
    "    ######predicts_body_V2 = model_body_V2.predict(x_test_body_V2, batch_size=8)\n",
    "    predicts_body_V2 = model_body_V2.predict(x_test_body_V2, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> La prédiction du Body est aussi longue avec le plongement : 4h30 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54min 32s, sys: 1min 53s, total: 56min 25s\n",
      "Wall time: 8min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    model_title.load_weights('./MODELS/elmo-model-title.h5')  \n",
    "    predicts_title = model_title.predict(x_test_title, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On fait une sauvegarde intermédiaire des données pour pouvoir les analyser après coup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predicts_title).to_csv('res_body_clean2/V1_predict_title.csv', index=True)\n",
    "pd.DataFrame(predicts_body_V2).to_csv('res_body_clean2/V1_predict_body_clean.csv', index=True)\n",
    "pd.DataFrame(y_test).to_csv('res_body_clean2/V1_y_test.csv', index=True)\n",
    "#####pd.DataFrame(y_test_global).to_csv('res_body_clean2/V1_y_test_global.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seb/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/seb/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/seb/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "## On décode\n",
    "m_predicts_title = decode(le, predicts_title)\n",
    "m_predicts_body_V2 = decode(le, predicts_body_V2)\n",
    "m_y_test = decode(le, y_test)\n",
    "\n",
    "pd.DataFrame(m_predicts_title).to_csv('res_body_clean2/V2_predict_title.csv', index=True)\n",
    "pd.DataFrame(m_predicts_body_V2).to_csv('res_body_clean2/V2_predict_body_clean.csv', index=True)\n",
    "pd.DataFrame(m_y_test).to_csv('res_body_clean2/V2_y_test.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets décodés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_predicts_title = pd.DataFrame(np.where(m_predicts_title=='non', 0, 1), columns=['python'])\n",
    "mm_predicts_body_V2 = pd.DataFrame(np.where(m_predicts_body_V2=='non', 0, 1), columns=['python'])\n",
    "mm_y_test = pd.DataFrame(np.where(m_y_test=='non', 0, 1), columns=['python'])\n",
    "\n",
    "mm_predicts_title.to_csv('res_body_clean2/V3_predict_title.csv', index=True)\n",
    "mm_predicts_body_V2.to_csv('res_body_clean2/V3_predict_body_clean.csv', index=True)\n",
    "mm_y_test.to_csv('res_body_clean2/V3_y_test.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fabrication du Dataset OR entre les prédiction du Titre et du Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_predicts_title_OR_body_V2 = pd.DataFrame(\n",
    "    np.where(np.logical_or(mm_predicts_title, mm_predicts_body_V2), 1, 0),\n",
    "    columns=mm_predicts_title.columns, index=mm_predicts_title.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mesure de la performance de la version ELMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>python_title</th>\n",
       "      <td>0.395574</td>\n",
       "      <td>0.256043</td>\n",
       "      <td>0.9126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python_body</th>\n",
       "      <td>0.118812</td>\n",
       "      <td>0.0644584</td>\n",
       "      <td>0.8932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python_OR</th>\n",
       "      <td>0.432181</td>\n",
       "      <td>0.290958</td>\n",
       "      <td>0.9146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1_score     recall accuracy_score\n",
       "python_title  0.395574   0.256043         0.9126\n",
       "python_body   0.118812  0.0644584         0.8932\n",
       "python_OR     0.432181   0.290958         0.9146"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "l_tags = ['python']\n",
    "m_ELMO2_body = pd.DataFrame(index=l_tags, \n",
    "                        columns=['f1_score', 'recall', 'accuracy_score'])\n",
    "m_ELMO2_title = pd.DataFrame(index=l_tags, \n",
    "                        columns=['f1_score', 'recall', 'accuracy_score'])\n",
    "m_ELMO2_title_OR_body = pd.DataFrame(index=l_tags, \n",
    "                        columns=['f1_score', 'recall', 'accuracy_score'])\n",
    "\n",
    "for i_y_pred, col in enumerate(l_tags):\n",
    "    # Title\n",
    "    m_ELMO2_title.loc[col, 'f1_score'] = f1_score(\n",
    "        y_true=mm_y_test[col].ravel(), \n",
    "        y_pred=mm_predicts_title[col].to_dense().ravel())\n",
    "    \n",
    "    m_ELMO2_title.loc[col, 'recall'] = recall_score(\n",
    "        y_true=mm_y_test[col].ravel(), \n",
    "        y_pred=mm_predicts_title[col].to_dense().ravel())\n",
    "    \n",
    "    m_ELMO2_title.loc[col, 'accuracy_score'] = accuracy_score(\n",
    "        y_true=mm_y_test[col].ravel(), \n",
    "        y_pred=mm_predicts_title[col].to_dense().ravel())\n",
    "    \n",
    "    # Body\n",
    "    m_ELMO2_body.loc[col, 'f1_score'] = f1_score(\n",
    "        y_true=mm_y_test[col].ravel(), \n",
    "        y_pred=mm_predicts_body_V2[col].to_dense().ravel())\n",
    "    \n",
    "    m_ELMO2_body.loc[col, 'recall'] = recall_score(\n",
    "        y_true=mm_y_test[col].ravel(), \n",
    "        y_pred=mm_predicts_body_V2[col].to_dense().ravel())\n",
    "    \n",
    "    m_ELMO2_body.loc[col, 'accuracy_score'] = accuracy_score(\n",
    "        y_true=mm_y_test[col].ravel(), \n",
    "        y_pred=mm_predicts_body_V2[col].to_dense().ravel())\n",
    "    \n",
    "    # Title OR Body\n",
    "    m_ELMO2_title_OR_body.loc[col, 'f1_score'] = f1_score(\n",
    "        y_true=mm_y_test[col].ravel(), \n",
    "        y_pred=mm_predicts_title_OR_body_V2[col].to_dense().ravel())\n",
    "    \n",
    "    m_ELMO2_title_OR_body.loc[col, 'recall'] = recall_score(\n",
    "        y_true=mm_y_test[col].ravel(), \n",
    "        y_pred=mm_predicts_title_OR_body_V2[col].to_dense().ravel())\n",
    "    \n",
    "    m_ELMO2_title_OR_body.loc[col, 'accuracy_score'] = accuracy_score(\n",
    "        y_true=mm_y_test[col].ravel(), \n",
    "        y_pred=mm_predicts_title_OR_body_V2[col].to_dense().ravel())\n",
    "    \n",
    "Total_python = pd.concat([m_ELMO2_title, m_ELMO2_body, m_ELMO2_title_OR_body], )\n",
    "Total_python.index=['python_title', 'python_body', 'python_OR']\n",
    "Total_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Les résultats sont très mauvais car très faibles notamment au niveau du body\n",
    "\n",
    "> Les résultats (accuracy) sont cependant très proches des scores d'entrainement des réseaux : \n",
    "> - Pour le title 0.9126 en test vs 0.9124 à l'entrainement\n",
    "> - Pour le body 0.8932 en test vs 0.8949 à l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
