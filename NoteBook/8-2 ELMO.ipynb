{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk\n",
    "import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'data/QueryResults3_new.csv'\n",
    "df1 = pd.read_csv(file1,index_col=['Id'])\n",
    "\n",
    "import mes_fonctions_final2 as stt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "StopWord = stt.load_stop_word()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/!\\ Ajout des features en cours\n"
     ]
    }
   ],
   "source": [
    "Y_tags, Y_tags_voc = stt.genere_target_dummy_and_vocabulary(data=df1, min_df=300)\n",
    "Tags_freq = stt.genere_df_target_tags_freq(data=df1, min_df=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtre de X_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin Train_Split : 0:00:00.068843\n"
     ]
    }
   ],
   "source": [
    "# On sépare les données d'entrainement de celles de tests\n",
    "debut = datetime.datetime.now()\n",
    "X = df1['Body']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_tags, test_size=0.2, random_state=42 )\n",
    "fin = datetime.datetime.now()\n",
    "print(\"Fin Train_Split : {}\".format(fin-debut))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation Title / Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERSION TITLE\n",
    "X_train_Title = df1.loc[X_train.index, 'Title']\n",
    "X_test_Title = df1.loc[X_test.index, 'Title']\n",
    "\n",
    "train_title = pd.DataFrame(X_train_Title)\n",
    "test_title = pd.DataFrame(X_test_Title)\n",
    "train_title.columns = ['post']\n",
    "test_title.columns = ['post']\n",
    "\n",
    "# VERSION BODY\n",
    "X_train_body = df1.loc[X_train.index, 'Body']\n",
    "X_test_body = df1.loc[X_test.index, 'Body']\n",
    "\n",
    "train_body = pd.DataFrame(X_train_body)\n",
    "test_body = pd.DataFrame(X_test_body)\n",
    "train_body.columns = ['post']\n",
    "test_body.columns = ['post']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELMO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On Charge le modèle pré-entrainé d'ELMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /var/folders/95/fydcf18x5rz7wljn4wqt_tq00000gn/T/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/elmo/2'.\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/elmo/2: 60.35MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/elmo/2: 120.35MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/elmo/2: 180.35MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/elmo/2: 230.35MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/elmo/2: 290.35MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/elmo/2: 350.35MB\n",
      "INFO:tensorflow:Downloaded https://tfhub.dev/google/elmo/2, Total size: 357.40MB\n",
      "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/elmo/2'.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://tfhub.dev/google/elmo/2\"\n",
    "embed = hub.Module(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On encode les features cibles : \n",
    "> uniquement sur python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Y \n",
    "y1 = np.where(Y_train['python'].to_dense()==0, 'non', 'python')\n",
    "y2 = np.where(Y_test['python'].to_dense()==0, 'non', 'python')\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y1)\n",
    "\n",
    "def encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def decode(le, one_hot):\n",
    "    dec = np.argmax(one_hot, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = np.asarray(encode(le, y1))\n",
    "y_test = np.asarray(encode(le, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On transforme les X en np.array\n",
    "\n",
    "x_train_title = np.asarray(X_train_Title)\n",
    "x_train_body = np.asarray(X_train_body)\n",
    "\n",
    "x_test_title = np.asarray(X_test_Title)\n",
    "x_test_body = np.asarray(X_test_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramétrage des MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Partie Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Lambda, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "\n",
    "def ELMoEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
    "\n",
    "input_text_title = Input(shape=(1,), dtype=tf.string)\n",
    "embedding_title = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text_title)\n",
    "dense_title = Dense(256, activation='relu')(embedding_title)\n",
    "pred_title = Dense(2, activation='softmax')(dense_title)\n",
    "model_title = Model(inputs=[input_text_title], outputs=pred_title)\n",
    "model_title.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Partie Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "input_text_body = Input(shape=(1,), dtype=tf.string)\n",
    "embedding_body = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text_body)\n",
    "dense_body = Dense(256, activation='relu')(embedding_body)\n",
    "pred_body = Dense(2, activation='softmax')(dense_body)\n",
    "model_body = Model(inputs=[input_text_body], outputs=pred_body)\n",
    "model_body.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement des 2 modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du RNN pour le Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 53262s 1s/step - loss: 0.2883 - acc: 0.8970\n",
      "CPU times: user 4d 41min 41s, sys: 2h 27min 9s, total: 4d 3h 8min 50s\n",
      "Wall time: 14h 47min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    ####history_body = model_body.fit(x_train_body, y_train, epochs=1, batch_size=32)\n",
    "    history_body = model_body.fit(x_train_body, y_train, epochs=1, batch_size=8)\n",
    "    model_body.save_weights('./elmo-model-body.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> L'Entrainement aura duré 18h "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du RNN pour le Titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    history_title = model_title.fit(x_train_title, y_train, epochs=1, batch_size=32)\n",
    "    model_title.save_weights('./elmo-model-title.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> L'Entrainement est ici beaucoup plus rapide : 36 min car il y a beaucoup moins de mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction & Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39min 43s, sys: 42.3 s, total: 40min 26s\n",
      "Wall time: 6min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    model_title.load_weights('./elmo-model-title.h5')  \n",
    "    predicts_title = model_title.predict(x_test_title, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seb/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_preds_title2 = decode(le, predicts_title)\n",
    "\n",
    "df_y_test_title = pd.DataFrame(np.where(y_test=='non', 0, 1), columns=['python'])\n",
    "df_y_preds_title = pd.DataFrame(np.where(y_preds_title2=='non', 0, 1), columns=['python'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22h 48min 18s, sys: 35min 50s, total: 23h 24min 8s\n",
      "Wall time: 3h 29min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    model_body.load_weights('./elmo-model-body.h5')  \n",
    "    predicts_body = model_body.predict(x_test_body, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> La prédiction du Body est aussi longue avec le plongement : 3h30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = predicts_body.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mesure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8729  154]\n",
      " [ 763  354]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        non       0.92      0.98      0.95      8883\n",
      "     python       0.70      0.32      0.44      1117\n",
      "\n",
      "avg / total       0.89      0.91      0.89     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seb/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/seb/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_test = decode(le, y_test)\n",
    "y_preds = decode(le, predicts)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_preds))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On fait une sauvegarde intermédiaire des données pour pouvoir les analyser après coup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_y_test_body = pd.DataFrame(y_test)\n",
    "#df_y_preds_body = pd.DataFrame(y_preds)\n",
    "y_test = decode(le, y_test)\n",
    "y_preds = decode(le, predicts)\n",
    "\n",
    "df_y_test_body = pd.DataFrame(np.where(y_test=='non', 0, 1), columns=['python'])\n",
    "df_y_preds_body = pd.DataFrame(np.where(y_preds=='non', 0, 1), columns=['python'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_body_OR_title = pd.DataFrame(\n",
    "    np.where(np.logical_or(df_y_preds_title, df_y_preds_body), 1, 0),\n",
    "    columns=df_y_preds_title.columns, index=df_y_preds_title.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_test_body.to_csv('ELMO_y_test_body_python.csv', index=True)\n",
    "df_y_preds_title.to_csv('ELMO_y_preds_title_python.csv', index=True)\n",
    "df_y_preds_body.to_csv('ELMO_y_preds_body_python.csv', index=True)\n",
    "df_y_body_OR_title.to_csv('ELMO_y_preds_title_OR_body_python.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>python_title</th>\n",
       "      <td>0.522262</td>\n",
       "      <td>0.388541</td>\n",
       "      <td>0.9206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python_body</th>\n",
       "      <td>0.435692</td>\n",
       "      <td>0.31692</td>\n",
       "      <td>0.9083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python_OR</th>\n",
       "      <td>0.634171</td>\n",
       "      <td>0.564906</td>\n",
       "      <td>0.9272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1_score    recall accuracy_score\n",
       "python_title  0.522262  0.388541         0.9206\n",
       "python_body   0.435692   0.31692         0.9083\n",
       "python_OR     0.634171  0.564906         0.9272"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "l_tags = ['python']\n",
    "m_ELMO1_body = pd.DataFrame(index=l_tags, \n",
    "                        columns=['f1_score', 'recall', 'accuracy_score'])\n",
    "m_ELMO1_title = pd.DataFrame(index=l_tags, \n",
    "                        columns=['f1_score', 'recall', 'accuracy_score'])\n",
    "m_ELMO1_title_OR_body = pd.DataFrame(index=l_tags, \n",
    "                        columns=['f1_score', 'recall', 'accuracy_score'])\n",
    "\n",
    "for i_y_pred, col in enumerate(l_tags):\n",
    "    # Title\n",
    "    m_ELMO1_title.loc[col, 'f1_score'] = f1_score(\n",
    "        y_true=df_y_test_title[col].ravel(), \n",
    "        y_pred=df_y_preds_title[col].to_dense().ravel())\n",
    "    \n",
    "    m_ELMO1_title.loc[col, 'recall'] = recall_score(\n",
    "        y_true=df_y_test_title[col].ravel(), \n",
    "        y_pred=df_y_preds_title[col].to_dense().ravel())\n",
    "    \n",
    "    m_ELMO1_title.loc[col, 'accuracy_score'] = accuracy_score(\n",
    "        y_true=df_y_test_title[col].ravel(), \n",
    "        y_pred=df_y_preds_title[col].to_dense().ravel())\n",
    "    \n",
    "    # Body\n",
    "    m_ELMO1_body.loc[col, 'f1_score'] = f1_score(\n",
    "        y_true=df_y_test_body[col].ravel(), \n",
    "        y_pred=df_y_preds_body[col].to_dense().ravel())\n",
    "    \n",
    "    m_ELMO1_body.loc[col, 'recall'] = recall_score(\n",
    "        y_true=df_y_test_body[col].ravel(), \n",
    "        y_pred=df_y_preds_body[col].to_dense().ravel())\n",
    "    \n",
    "    m_ELMO1_body.loc[col, 'accuracy_score'] = accuracy_score(\n",
    "        y_true=df_y_test_body[col].ravel(), \n",
    "        y_pred=df_y_preds_body[col].to_dense().ravel())\n",
    "    \n",
    "    # Title OR Body\n",
    "    m_ELMO1_title_OR_body.loc[col, 'f1_score'] = f1_score(\n",
    "        y_true=df_y_test_body[col].ravel(), \n",
    "        y_pred=df_y_body_OR_title[col].to_dense().ravel())\n",
    "    \n",
    "    m_ELMO1_title_OR_body.loc[col, 'recall'] = recall_score(\n",
    "        y_true=df_y_test_body[col].ravel(), \n",
    "        y_pred=df_y_body_OR_title[col].to_dense().ravel())\n",
    "    \n",
    "    m_ELMO1_title_OR_body.loc[col, 'accuracy_score'] = accuracy_score(\n",
    "        y_true=df_y_test_body[col].ravel(), \n",
    "        y_pred=df_y_body_OR_title[col].to_dense().ravel())\n",
    "    \n",
    "Total_python = pd.concat([m_ELMO1_title, m_ELMO1_body, m_ELMO1_title_OR_body], )\n",
    "Total_python.index=['python_title', 'python_body', 'python_OR']\n",
    "Total_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Les résultats sont assez décevants par rapport aux autres méthodes mais on reste sur des valeurs qui sont tout de même bonnes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
